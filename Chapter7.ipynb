{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter7",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/NQQaJSfPTCySBO7JpH7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngchul-sung/start-tf2-programming/blob/master/Chapter7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpzhN-DDXahk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9392f1a9-eaad-41a5-dced-b4ff53835187"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JecCTYgnXijh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 7.1 SimpleRNN 레이어 생성 코드\n",
        "rnn1 = tf.keras.layers.SimpleRNN(units=1, activation='tanh', return_sequences=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rFRjzZbXp4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "d16b9565-0f95-4d53-8f95-a90bc7da8dbb"
      },
      "source": [
        "# 7.2 시퀀스 예측 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(6):\n",
        "    # [0,1,2,3], [1,2,3,4] 같은 정수의 시퀀스를 만듭니다.\n",
        "    lst = list(range(i,i+4))\n",
        "\n",
        "    # 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장합니다.\n",
        "    # SimpleRNN 에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장합니다.\n",
        "    X.append(list(map(lambda c: [c/10], lst)))\n",
        "\n",
        "    # 정답에 해당하는 4, 5 등의 정수를 역시 위처럼 10으로 나눠서 저장합니다.\n",
        "    Y.append((i+4)/10)\n",
        "    \n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "for i in range(len(X)):\n",
        "    print(X[i], Y[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. ]\n",
            " [0.1]\n",
            " [0.2]\n",
            " [0.3]] 0.4\n",
            "[[0.1]\n",
            " [0.2]\n",
            " [0.3]\n",
            " [0.4]] 0.5\n",
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]] 0.6\n",
            "[[0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]] 0.7\n",
            "[[0.4]\n",
            " [0.5]\n",
            " [0.6]\n",
            " [0.7]] 0.8\n",
            "[[0.5]\n",
            " [0.6]\n",
            " [0.7]\n",
            " [0.8]] 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFh84rVX1wR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "c131de04-fa76-496a-8894-c232ca528b86"
      },
      "source": [
        "# 7.3 시퀀스 예측 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXvJ9ZpXX36J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "56b456d2-b726-4810-c844-2cdcebfd84dd"
      },
      "source": [
        "# 7.4 네트워크 훈련 및 결과 확인\n",
        "model.fit(X, Y, epochs=100, verbose=0)\n",
        "print(model.predict(X))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.34461868]\n",
            " [0.522703  ]\n",
            " [0.6552525 ]\n",
            " [0.74366874]\n",
            " [0.7945035 ]\n",
            " [0.815141  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u9fO1xUYKZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "07268c13-88d1-44f2-f189-d380d43d83c4"
      },
      "source": [
        "# 7.5 학습되지 않은 시퀀스에 대한 예측 결과\n",
        "print(model.predict(np.array([[[0.6],[0.7],[0.8],[0.9]]])))\n",
        "print(model.predict(np.array([[[-0.1],[0.0],[0.1],[0.2]]])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8123374]]\n",
            "[[0.13207716]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0lF9N4YOYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23243b17-5d86-4382-aded-1f6102dbe1c0"
      },
      "source": [
        "# 7.6 곱셈 문제 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(3000):\n",
        "    # 0~1 사이의 랜덤한 숫자 100 개를 만듭니다.\n",
        "    lst = np.random.rand(100)\n",
        "    # 마킹할 숫자 2개의 인덱스를 뽑습니다.\n",
        "    idx = np.random.choice(100, 2, replace=False)\n",
        "    # 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다.\n",
        "    zeros = np.zeros(100)\n",
        "    zeros[idx] = 1\n",
        "    # 마킹 인덱스와 랜덤한 숫자를 합쳐서 X 에 저장합니다.\n",
        "    X.append(np.array(list(zip(zeros, lst))))\n",
        "    # 마킹 인덱스가 1인 값들만 서로 곱해서 Y 에 저장합니다.\n",
        "    Y.append(np.prod(lst[idx]))\n",
        "    \n",
        "print(X[0], Y[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.30368489]\n",
            " [0.         0.78910309]\n",
            " [0.         0.22245149]\n",
            " [0.         0.15271601]\n",
            " [0.         0.15455128]\n",
            " [0.         0.55559807]\n",
            " [0.         0.19988398]\n",
            " [0.         0.89911759]\n",
            " [0.         0.52737961]\n",
            " [0.         0.78205865]\n",
            " [0.         0.18558637]\n",
            " [0.         0.5023655 ]\n",
            " [0.         0.12033025]\n",
            " [0.         0.49188363]\n",
            " [0.         0.59222643]\n",
            " [0.         0.91237911]\n",
            " [0.         0.89147605]\n",
            " [0.         0.19980285]\n",
            " [0.         0.39922542]\n",
            " [0.         0.91146961]\n",
            " [0.         0.12606129]\n",
            " [0.         0.39430348]\n",
            " [0.         0.67550638]\n",
            " [0.         0.86614383]\n",
            " [0.         0.43802091]\n",
            " [0.         0.83810176]\n",
            " [0.         0.13652229]\n",
            " [0.         0.68170204]\n",
            " [0.         0.55088314]\n",
            " [0.         0.68561036]\n",
            " [0.         0.29584247]\n",
            " [0.         0.63790272]\n",
            " [0.         0.34235445]\n",
            " [0.         0.1355643 ]\n",
            " [0.         0.84807258]\n",
            " [0.         0.51566954]\n",
            " [0.         0.02661618]\n",
            " [0.         0.36001058]\n",
            " [0.         0.59724534]\n",
            " [0.         0.76505484]\n",
            " [1.         0.50209689]\n",
            " [0.         0.8385914 ]\n",
            " [0.         0.04706605]\n",
            " [0.         0.76125333]\n",
            " [0.         0.37741686]\n",
            " [0.         0.8414032 ]\n",
            " [0.         0.69556998]\n",
            " [0.         0.73149261]\n",
            " [1.         0.84338809]\n",
            " [0.         0.04649078]\n",
            " [0.         0.99406552]\n",
            " [0.         0.80716485]\n",
            " [0.         0.40388677]\n",
            " [0.         0.02713029]\n",
            " [0.         0.56290755]\n",
            " [0.         0.71378998]\n",
            " [0.         0.91900374]\n",
            " [0.         0.27319513]\n",
            " [0.         0.97610104]\n",
            " [0.         0.19785544]\n",
            " [0.         0.60740445]\n",
            " [0.         0.46034758]\n",
            " [0.         0.11431247]\n",
            " [0.         0.05181149]\n",
            " [0.         0.27089619]\n",
            " [0.         0.61886313]\n",
            " [0.         0.47645621]\n",
            " [0.         0.58078427]\n",
            " [0.         0.56620011]\n",
            " [0.         0.26309553]\n",
            " [0.         0.61682645]\n",
            " [0.         0.82519553]\n",
            " [0.         0.55335288]\n",
            " [0.         0.11418644]\n",
            " [0.         0.97875159]\n",
            " [0.         0.99084583]\n",
            " [0.         0.7657332 ]\n",
            " [0.         0.71531221]\n",
            " [0.         0.74409201]\n",
            " [0.         0.8137245 ]\n",
            " [0.         0.44946602]\n",
            " [0.         0.69761013]\n",
            " [0.         0.15340207]\n",
            " [0.         0.51003149]\n",
            " [0.         0.03198531]\n",
            " [0.         0.09322258]\n",
            " [0.         0.31076357]\n",
            " [0.         0.13037261]\n",
            " [0.         0.07749   ]\n",
            " [0.         0.94262352]\n",
            " [0.         0.43454575]\n",
            " [0.         0.30832945]\n",
            " [0.         0.90075817]\n",
            " [0.         0.42838142]\n",
            " [0.         0.88715785]\n",
            " [0.         0.32177547]\n",
            " [0.         0.45861842]\n",
            " [0.         0.11839723]\n",
            " [0.         0.56563985]\n",
            " [0.         0.20550955]] 0.42346253860074196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY2UJrqTckWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cf525479-633c-489d-c24f-ef5f645df15c"
      },
      "source": [
        "# 7.7 SimpleRNN 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.SimpleRNN(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (None, 100, 30)           990       \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 30)                1830      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 2,851\n",
            "Trainable params: 2,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMlSsHQjc9vH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3ffebdb-046d-435e-bf4e-5890efae83d7"
      },
      "source": [
        "# 7.8 SimpleRNN 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "# 2560개의 데이터만 학습시킵니다. validation 데이터는 20% 로 지정합니다.\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2048 samples, validate on 512 samples\n",
            "Epoch 1/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0752 - val_loss: 0.0485\n",
            "Epoch 2/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0471 - val_loss: 0.0474\n",
            "Epoch 3/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0473 - val_loss: 0.0497\n",
            "Epoch 4/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0461 - val_loss: 0.0482\n",
            "Epoch 5/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0464 - val_loss: 0.0478\n",
            "Epoch 6/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0458 - val_loss: 0.0475\n",
            "Epoch 7/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0468 - val_loss: 0.0474\n",
            "Epoch 8/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0463 - val_loss: 0.0494\n",
            "Epoch 9/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0464 - val_loss: 0.0477\n",
            "Epoch 10/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0458 - val_loss: 0.0472\n",
            "Epoch 11/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0453 - val_loss: 0.0476\n",
            "Epoch 12/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0459 - val_loss: 0.0470\n",
            "Epoch 13/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0451 - val_loss: 0.0495\n",
            "Epoch 14/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0462 - val_loss: 0.0478\n",
            "Epoch 15/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0457 - val_loss: 0.0472\n",
            "Epoch 16/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0459 - val_loss: 0.0474\n",
            "Epoch 17/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0449 - val_loss: 0.0474\n",
            "Epoch 18/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0449 - val_loss: 0.0500\n",
            "Epoch 19/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0456 - val_loss: 0.0495\n",
            "Epoch 20/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 21/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 22/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0444 - val_loss: 0.0478\n",
            "Epoch 23/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0445 - val_loss: 0.0490\n",
            "Epoch 24/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0445 - val_loss: 0.0477\n",
            "Epoch 25/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0451 - val_loss: 0.0477\n",
            "Epoch 26/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0449 - val_loss: 0.0480\n",
            "Epoch 27/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0456 - val_loss: 0.0472\n",
            "Epoch 28/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0442 - val_loss: 0.0481\n",
            "Epoch 29/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0443 - val_loss: 0.0484\n",
            "Epoch 30/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0461 - val_loss: 0.0505\n",
            "Epoch 31/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0437 - val_loss: 0.0477\n",
            "Epoch 32/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0435 - val_loss: 0.0477\n",
            "Epoch 33/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0446 - val_loss: 0.0510\n",
            "Epoch 34/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0439 - val_loss: 0.0473\n",
            "Epoch 35/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0434 - val_loss: 0.0493\n",
            "Epoch 36/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0433 - val_loss: 0.0493\n",
            "Epoch 37/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0437 - val_loss: 0.0489\n",
            "Epoch 38/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0430 - val_loss: 0.0524\n",
            "Epoch 39/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0439 - val_loss: 0.0469\n",
            "Epoch 40/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 41/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0425 - val_loss: 0.0478\n",
            "Epoch 42/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0428 - val_loss: 0.0473\n",
            "Epoch 43/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0428 - val_loss: 0.0487\n",
            "Epoch 44/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0422 - val_loss: 0.0491\n",
            "Epoch 45/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0439 - val_loss: 0.0497\n",
            "Epoch 46/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0413 - val_loss: 0.0515\n",
            "Epoch 47/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0415 - val_loss: 0.0500\n",
            "Epoch 48/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0422 - val_loss: 0.0504\n",
            "Epoch 49/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0417 - val_loss: 0.0501\n",
            "Epoch 50/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0421 - val_loss: 0.0497\n",
            "Epoch 51/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0405 - val_loss: 0.0498\n",
            "Epoch 52/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0409 - val_loss: 0.0515\n",
            "Epoch 53/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0402 - val_loss: 0.0587\n",
            "Epoch 54/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0412 - val_loss: 0.0520\n",
            "Epoch 55/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0403 - val_loss: 0.0480\n",
            "Epoch 56/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0407 - val_loss: 0.0510\n",
            "Epoch 57/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0405 - val_loss: 0.0526\n",
            "Epoch 58/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0398 - val_loss: 0.0512\n",
            "Epoch 59/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0396 - val_loss: 0.0533\n",
            "Epoch 60/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0397 - val_loss: 0.0537\n",
            "Epoch 61/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0387 - val_loss: 0.0567\n",
            "Epoch 62/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0396 - val_loss: 0.0517\n",
            "Epoch 63/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0385 - val_loss: 0.0498\n",
            "Epoch 64/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0399 - val_loss: 0.0546\n",
            "Epoch 65/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0387 - val_loss: 0.0554\n",
            "Epoch 66/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0384 - val_loss: 0.0538\n",
            "Epoch 67/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0378 - val_loss: 0.0541\n",
            "Epoch 68/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0379 - val_loss: 0.0516\n",
            "Epoch 69/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0372 - val_loss: 0.0540\n",
            "Epoch 70/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0371 - val_loss: 0.0510\n",
            "Epoch 71/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0382 - val_loss: 0.0530\n",
            "Epoch 72/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0362 - val_loss: 0.0549\n",
            "Epoch 73/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0364 - val_loss: 0.0560\n",
            "Epoch 74/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0369 - val_loss: 0.0577\n",
            "Epoch 75/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0360 - val_loss: 0.0542\n",
            "Epoch 76/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0349 - val_loss: 0.0589\n",
            "Epoch 77/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0348 - val_loss: 0.0563\n",
            "Epoch 78/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0350 - val_loss: 0.0565\n",
            "Epoch 79/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0349 - val_loss: 0.0533\n",
            "Epoch 80/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0334 - val_loss: 0.0593\n",
            "Epoch 81/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0339 - val_loss: 0.0565\n",
            "Epoch 82/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0331 - val_loss: 0.0598\n",
            "Epoch 83/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0335 - val_loss: 0.0575\n",
            "Epoch 84/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0320 - val_loss: 0.0569\n",
            "Epoch 85/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0324 - val_loss: 0.0597\n",
            "Epoch 86/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0325 - val_loss: 0.0591\n",
            "Epoch 87/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0322 - val_loss: 0.0583\n",
            "Epoch 88/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0311 - val_loss: 0.0655\n",
            "Epoch 89/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0312 - val_loss: 0.0607\n",
            "Epoch 90/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0311 - val_loss: 0.0587\n",
            "Epoch 91/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0305 - val_loss: 0.0634\n",
            "Epoch 92/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0298 - val_loss: 0.0644\n",
            "Epoch 93/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0292 - val_loss: 0.0650\n",
            "Epoch 94/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0286 - val_loss: 0.0656\n",
            "Epoch 95/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0288 - val_loss: 0.0630\n",
            "Epoch 96/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0290 - val_loss: 0.0660\n",
            "Epoch 97/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0281 - val_loss: 0.0636\n",
            "Epoch 98/100\n",
            "2048/2048 [==============================] - 6s 3ms/sample - loss: 0.0270 - val_loss: 0.0662\n",
            "Epoch 99/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0271 - val_loss: 0.0625\n",
            "Epoch 100/100\n",
            "2048/2048 [==============================] - 7s 3ms/sample - loss: 0.0263 - val_loss: 0.0650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-f26zEcdKgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "22a856b5-77f3-4b42-9dab-9b47161043a2"
      },
      "source": [
        "# 7.9 SimpleRNN 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHc0-sQshHQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4b8e8e69-d614-4769-f70f-16496049bd99"
      },
      "source": [
        "# 7.10 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "# 5개 테스트 데이터에 대한 예측을 표시합니다.\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "    # 오차가 0.04 이상이면 오답입니다.\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        fail += 1\n",
        "print('correctness:', (440 - fail) / 440 * 100, '%')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440/440 [==============================] - 0s 805us/sample - loss: 0.0674\n",
            "0.3086555988413602 \t 0.6564365 \tdiff: 0.347780904092142\n",
            "0.0068629519465001464 \t 0.48841658 \tdiff: 0.48155363039946236\n",
            "0.5237953747841952 \t 0.12759723 \tdiff: 0.3961981470915912\n",
            "0.08709619625243772 \t 0.32435048 \tdiff: 0.2372542800125159\n",
            "0.4376509525255051 \t 0.15827335 \tdiff: 0.2793775983527985\n",
            "correctness: 10.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG9n9IOSiG_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d0bfafe7-931c-4ff6-a0c0-01711efbd2dd"
      },
      "source": [
        "# 7.11 LSTM 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.LSTM(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 30)           3960      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 11,311\n",
            "Trainable params: 11,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFnBpQViJbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30a2429b-477a-4438-9010-1a79745ac43f"
      },
      "source": [
        "# 7.12 LSTM 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2048 samples, validate on 512 samples\n",
            "Epoch 1/100\n",
            "2048/2048 [==============================] - 3s 2ms/sample - loss: 0.0498 - val_loss: 0.0465\n",
            "Epoch 2/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 0.0450 - val_loss: 0.0465\n",
            "Epoch 3/100\n",
            "2048/2048 [==============================] - 1s 352us/sample - loss: 0.0452 - val_loss: 0.0467\n",
            "Epoch 4/100\n",
            "2048/2048 [==============================] - 1s 345us/sample - loss: 0.0453 - val_loss: 0.0465\n",
            "Epoch 5/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0450 - val_loss: 0.0465\n",
            "Epoch 6/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0451 - val_loss: 0.0465\n",
            "Epoch 7/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0451 - val_loss: 0.0463\n",
            "Epoch 8/100\n",
            "2048/2048 [==============================] - 1s 345us/sample - loss: 0.0450 - val_loss: 0.0464\n",
            "Epoch 9/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0450 - val_loss: 0.0464\n",
            "Epoch 10/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0447 - val_loss: 0.0461\n",
            "Epoch 11/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 0.0445 - val_loss: 0.0479\n",
            "Epoch 12/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0450 - val_loss: 0.0462\n",
            "Epoch 13/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 0.0447 - val_loss: 0.0458\n",
            "Epoch 14/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 0.0446 - val_loss: 0.0462\n",
            "Epoch 15/100\n",
            "2048/2048 [==============================] - 1s 341us/sample - loss: 0.0445 - val_loss: 0.0464\n",
            "Epoch 16/100\n",
            "2048/2048 [==============================] - 1s 364us/sample - loss: 0.0445 - val_loss: 0.0456\n",
            "Epoch 17/100\n",
            "2048/2048 [==============================] - 1s 359us/sample - loss: 0.0444 - val_loss: 0.0454\n",
            "Epoch 18/100\n",
            "2048/2048 [==============================] - 1s 358us/sample - loss: 0.0445 - val_loss: 0.0459\n",
            "Epoch 19/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0445 - val_loss: 0.0465\n",
            "Epoch 20/100\n",
            "2048/2048 [==============================] - 1s 352us/sample - loss: 0.0443 - val_loss: 0.0486\n",
            "Epoch 21/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 0.0442 - val_loss: 0.0463\n",
            "Epoch 22/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0435 - val_loss: 0.0460\n",
            "Epoch 23/100\n",
            "2048/2048 [==============================] - 1s 353us/sample - loss: 0.0440 - val_loss: 0.0441\n",
            "Epoch 24/100\n",
            "2048/2048 [==============================] - 1s 354us/sample - loss: 0.0446 - val_loss: 0.0455\n",
            "Epoch 25/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0438 - val_loss: 0.0443\n",
            "Epoch 26/100\n",
            "2048/2048 [==============================] - 1s 355us/sample - loss: 0.0435 - val_loss: 0.0458\n",
            "Epoch 27/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 0.0443 - val_loss: 0.0454\n",
            "Epoch 28/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 0.0430 - val_loss: 0.0434\n",
            "Epoch 29/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0421 - val_loss: 0.0445\n",
            "Epoch 30/100\n",
            "2048/2048 [==============================] - 1s 361us/sample - loss: 0.0406 - val_loss: 0.0351\n",
            "Epoch 31/100\n",
            "2048/2048 [==============================] - 1s 356us/sample - loss: 0.0331 - val_loss: 0.0451\n",
            "Epoch 32/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0300 - val_loss: 0.0265\n",
            "Epoch 33/100\n",
            "2048/2048 [==============================] - 1s 356us/sample - loss: 0.0144 - val_loss: 0.0194\n",
            "Epoch 34/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 0.0158 - val_loss: 0.0203\n",
            "Epoch 35/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0095 - val_loss: 0.0123\n",
            "Epoch 36/100\n",
            "2048/2048 [==============================] - 1s 345us/sample - loss: 0.0085 - val_loss: 0.0110\n",
            "Epoch 37/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 0.0089 - val_loss: 0.0067\n",
            "Epoch 38/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0058 - val_loss: 0.0135\n",
            "Epoch 39/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0063 - val_loss: 0.0054\n",
            "Epoch 40/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0059 - val_loss: 0.0056\n",
            "Epoch 41/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0048 - val_loss: 0.0059\n",
            "Epoch 42/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0053 - val_loss: 0.0105\n",
            "Epoch 43/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 0.0050 - val_loss: 0.0054\n",
            "Epoch 44/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0041 - val_loss: 0.0088\n",
            "Epoch 45/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 0.0041 - val_loss: 0.0046\n",
            "Epoch 46/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 0.0039 - val_loss: 0.0029\n",
            "Epoch 47/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 0.0033 - val_loss: 0.0028\n",
            "Epoch 48/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 0.0025 - val_loss: 0.0033\n",
            "Epoch 49/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 50/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 51/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 52/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 53/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 54/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 55/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 0.0015 - val_loss: 0.0025\n",
            "Epoch 56/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 57/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 58/100\n",
            "2048/2048 [==============================] - 1s 344us/sample - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "2048/2048 [==============================] - 1s 354us/sample - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 60/100\n",
            "2048/2048 [==============================] - 1s 354us/sample - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 61/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 62/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 0.0010 - val_loss: 0.0015\n",
            "Epoch 63/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 64/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 7.8741e-04 - val_loss: 0.0011\n",
            "Epoch 65/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 6.9102e-04 - val_loss: 0.0014\n",
            "Epoch 66/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 9.2960e-04 - val_loss: 0.0013\n",
            "Epoch 67/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 8.5331e-04 - val_loss: 0.0019\n",
            "Epoch 68/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 0.0010 - val_loss: 9.5338e-04\n",
            "Epoch 69/100\n",
            "2048/2048 [==============================] - 1s 358us/sample - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 70/100\n",
            "2048/2048 [==============================] - 1s 365us/sample - loss: 0.0011 - val_loss: 9.1695e-04\n",
            "Epoch 71/100\n",
            "2048/2048 [==============================] - 1s 355us/sample - loss: 6.7339e-04 - val_loss: 0.0011\n",
            "Epoch 72/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 7.2759e-04 - val_loss: 8.6349e-04\n",
            "Epoch 73/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 7.1173e-04 - val_loss: 7.8726e-04\n",
            "Epoch 74/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 5.2922e-04 - val_loss: 8.3603e-04\n",
            "Epoch 75/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 4.9807e-04 - val_loss: 8.0305e-04\n",
            "Epoch 76/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 5.8132e-04 - val_loss: 7.1525e-04\n",
            "Epoch 77/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 5.6695e-04 - val_loss: 9.0741e-04\n",
            "Epoch 78/100\n",
            "2048/2048 [==============================] - 1s 343us/sample - loss: 5.6442e-04 - val_loss: 7.1399e-04\n",
            "Epoch 79/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 4.9748e-04 - val_loss: 9.1811e-04\n",
            "Epoch 80/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 5.0869e-04 - val_loss: 7.6622e-04\n",
            "Epoch 81/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 5.6750e-04 - val_loss: 6.9834e-04\n",
            "Epoch 82/100\n",
            "2048/2048 [==============================] - 1s 351us/sample - loss: 4.4435e-04 - val_loss: 0.0011\n",
            "Epoch 83/100\n",
            "2048/2048 [==============================] - 1s 345us/sample - loss: 4.8904e-04 - val_loss: 6.4190e-04\n",
            "Epoch 84/100\n",
            "2048/2048 [==============================] - 1s 348us/sample - loss: 5.8567e-04 - val_loss: 6.3730e-04\n",
            "Epoch 85/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 5.8303e-04 - val_loss: 7.0458e-04\n",
            "Epoch 86/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 5.2472e-04 - val_loss: 6.6945e-04\n",
            "Epoch 87/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 5.0931e-04 - val_loss: 4.8945e-04\n",
            "Epoch 88/100\n",
            "2048/2048 [==============================] - 1s 342us/sample - loss: 4.4762e-04 - val_loss: 8.0336e-04\n",
            "Epoch 89/100\n",
            "2048/2048 [==============================] - 1s 353us/sample - loss: 6.5294e-04 - val_loss: 0.0025\n",
            "Epoch 90/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 6.8195e-04 - val_loss: 4.5560e-04\n",
            "Epoch 91/100\n",
            "2048/2048 [==============================] - 1s 347us/sample - loss: 5.3937e-04 - val_loss: 6.3912e-04\n",
            "Epoch 92/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 5.0013e-04 - val_loss: 5.8146e-04\n",
            "Epoch 93/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 7.4820e-04 - val_loss: 0.0018\n",
            "Epoch 94/100\n",
            "2048/2048 [==============================] - 1s 346us/sample - loss: 5.0994e-04 - val_loss: 4.7029e-04\n",
            "Epoch 95/100\n",
            "2048/2048 [==============================] - 1s 355us/sample - loss: 3.1184e-04 - val_loss: 6.9021e-04\n",
            "Epoch 96/100\n",
            "2048/2048 [==============================] - 1s 355us/sample - loss: 4.5668e-04 - val_loss: 4.6703e-04\n",
            "Epoch 97/100\n",
            "2048/2048 [==============================] - 1s 360us/sample - loss: 3.5207e-04 - val_loss: 3.9282e-04\n",
            "Epoch 98/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 3.0893e-04 - val_loss: 3.5380e-04\n",
            "Epoch 99/100\n",
            "2048/2048 [==============================] - 1s 350us/sample - loss: 2.7039e-04 - val_loss: 3.4331e-04\n",
            "Epoch 100/100\n",
            "2048/2048 [==============================] - 1s 349us/sample - loss: 3.7916e-04 - val_loss: 4.0001e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Hbr-jJjkwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "49225b94-ede8-4caf-c7ce-2f7093307da2"
      },
      "source": [
        "# 7.13 LSTM 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzhK9McaEuf8HQwROkun9E8UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RShpj3ubjsF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1eccfe91-873f-43ae-9c88-76923bfe1545"
      },
      "source": [
        "# 7.14 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        cnt += 1\n",
        "print('correctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440/440 [==============================] - 0s 1ms/sample - loss: 3.1467e-04\n",
            "0.3086555988413602 \t 0.30174103 \tdiff: 0.006914565048864452\n",
            "0.0068629519465001464 \t 0.011822302 \tdiff: 0.004959349947926199\n",
            "0.5237953747841952 \t 0.5153989 \tdiff: 0.008396455201828301\n",
            "0.08709619625243772 \t 0.08126643 \tdiff: 0.005829763251873149\n",
            "0.4376509525255051 \t 0.43995708 \tdiff: 0.0023061297460708063\n",
            "correctness: 95.22727272727273 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcLHWFfUjwBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8f7ada36-0c39-4841-95b6-fc00f539e015"
      },
      "source": [
        "# 7.15 GRU 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.GRU(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 30)           3060      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 30)                5580      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 8,671\n",
            "Trainable params: 8,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfnnOyO-j2x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "507245ee-efb4-437c-c760-6054c7ece46b"
      },
      "source": [
        "# 7.16 GRU 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2048 samples, validate on 512 samples\n",
            "Epoch 1/100\n",
            "2048/2048 [==============================] - 3s 1ms/sample - loss: 0.0501 - val_loss: 0.0479\n",
            "Epoch 2/100\n",
            "2048/2048 [==============================] - 1s 402us/sample - loss: 0.0454 - val_loss: 0.0465\n",
            "Epoch 3/100\n",
            "2048/2048 [==============================] - 1s 391us/sample - loss: 0.0451 - val_loss: 0.0471\n",
            "Epoch 4/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 0.0453 - val_loss: 0.0465\n",
            "Epoch 5/100\n",
            "2048/2048 [==============================] - 1s 379us/sample - loss: 0.0453 - val_loss: 0.0467\n",
            "Epoch 6/100\n",
            "2048/2048 [==============================] - 1s 381us/sample - loss: 0.0452 - val_loss: 0.0463\n",
            "Epoch 7/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 0.0451 - val_loss: 0.0469\n",
            "Epoch 8/100\n",
            "2048/2048 [==============================] - 1s 398us/sample - loss: 0.0448 - val_loss: 0.0461\n",
            "Epoch 9/100\n",
            "2048/2048 [==============================] - 1s 386us/sample - loss: 0.0450 - val_loss: 0.0462\n",
            "Epoch 10/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 0.0449 - val_loss: 0.0459\n",
            "Epoch 11/100\n",
            "2048/2048 [==============================] - 1s 380us/sample - loss: 0.0450 - val_loss: 0.0460\n",
            "Epoch 12/100\n",
            "2048/2048 [==============================] - 1s 371us/sample - loss: 0.0446 - val_loss: 0.0458\n",
            "Epoch 13/100\n",
            "2048/2048 [==============================] - 1s 379us/sample - loss: 0.0445 - val_loss: 0.0455\n",
            "Epoch 14/100\n",
            "2048/2048 [==============================] - 1s 373us/sample - loss: 0.0443 - val_loss: 0.0455\n",
            "Epoch 15/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 0.0442 - val_loss: 0.0466\n",
            "Epoch 16/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 0.0447 - val_loss: 0.0450\n",
            "Epoch 17/100\n",
            "2048/2048 [==============================] - 1s 371us/sample - loss: 0.0433 - val_loss: 0.0433\n",
            "Epoch 18/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 0.0408 - val_loss: 0.0381\n",
            "Epoch 19/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 0.0245 - val_loss: 0.0123\n",
            "Epoch 20/100\n",
            "2048/2048 [==============================] - 1s 378us/sample - loss: 0.0080 - val_loss: 0.0047\n",
            "Epoch 21/100\n",
            "2048/2048 [==============================] - 1s 369us/sample - loss: 0.0032 - val_loss: 0.0030\n",
            "Epoch 22/100\n",
            "2048/2048 [==============================] - 1s 379us/sample - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 23/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 24/100\n",
            "2048/2048 [==============================] - 1s 382us/sample - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 25/100\n",
            "2048/2048 [==============================] - 1s 365us/sample - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 26/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 27/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 28/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 29/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 9.5994e-04 - val_loss: 0.0012\n",
            "Epoch 30/100\n",
            "2048/2048 [==============================] - 1s 368us/sample - loss: 9.5599e-04 - val_loss: 0.0013\n",
            "Epoch 31/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 9.5532e-04 - val_loss: 0.0012\n",
            "Epoch 32/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 7.5030e-04 - val_loss: 0.0012\n",
            "Epoch 33/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 7.3830e-04 - val_loss: 9.8143e-04\n",
            "Epoch 34/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 6.3380e-04 - val_loss: 8.6605e-04\n",
            "Epoch 35/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 6.1899e-04 - val_loss: 8.4887e-04\n",
            "Epoch 36/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 6.1211e-04 - val_loss: 8.2412e-04\n",
            "Epoch 37/100\n",
            "2048/2048 [==============================] - 1s 373us/sample - loss: 5.6324e-04 - val_loss: 8.8087e-04\n",
            "Epoch 38/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 5.3407e-04 - val_loss: 7.3041e-04\n",
            "Epoch 39/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 5.2062e-04 - val_loss: 7.4031e-04\n",
            "Epoch 40/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 5.6862e-04 - val_loss: 6.8027e-04\n",
            "Epoch 41/100\n",
            "2048/2048 [==============================] - 1s 369us/sample - loss: 4.3334e-04 - val_loss: 6.4913e-04\n",
            "Epoch 42/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 5.6573e-04 - val_loss: 6.2993e-04\n",
            "Epoch 43/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 4.2068e-04 - val_loss: 6.9286e-04\n",
            "Epoch 44/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 4.9293e-04 - val_loss: 6.2107e-04\n",
            "Epoch 45/100\n",
            "2048/2048 [==============================] - 1s 402us/sample - loss: 3.9297e-04 - val_loss: 0.0010\n",
            "Epoch 46/100\n",
            "2048/2048 [==============================] - 1s 391us/sample - loss: 4.7296e-04 - val_loss: 6.6814e-04\n",
            "Epoch 47/100\n",
            "2048/2048 [==============================] - 1s 378us/sample - loss: 4.8326e-04 - val_loss: 5.5026e-04\n",
            "Epoch 48/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 3.9836e-04 - val_loss: 6.9006e-04\n",
            "Epoch 49/100\n",
            "2048/2048 [==============================] - 1s 406us/sample - loss: 3.8445e-04 - val_loss: 5.0437e-04\n",
            "Epoch 50/100\n",
            "2048/2048 [==============================] - 1s 424us/sample - loss: 4.2149e-04 - val_loss: 4.9666e-04\n",
            "Epoch 51/100\n",
            "2048/2048 [==============================] - 1s 429us/sample - loss: 3.7378e-04 - val_loss: 5.8689e-04\n",
            "Epoch 52/100\n",
            "2048/2048 [==============================] - 1s 387us/sample - loss: 3.7715e-04 - val_loss: 6.9429e-04\n",
            "Epoch 53/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 3.2464e-04 - val_loss: 4.7674e-04\n",
            "Epoch 54/100\n",
            "2048/2048 [==============================] - 1s 401us/sample - loss: 2.8588e-04 - val_loss: 7.3485e-04\n",
            "Epoch 55/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 3.3771e-04 - val_loss: 5.8297e-04\n",
            "Epoch 56/100\n",
            "2048/2048 [==============================] - 1s 381us/sample - loss: 3.2538e-04 - val_loss: 4.8993e-04\n",
            "Epoch 57/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 3.0285e-04 - val_loss: 4.6356e-04\n",
            "Epoch 58/100\n",
            "2048/2048 [==============================] - 1s 373us/sample - loss: 2.7892e-04 - val_loss: 3.9061e-04\n",
            "Epoch 59/100\n",
            "2048/2048 [==============================] - 1s 373us/sample - loss: 2.4418e-04 - val_loss: 4.9582e-04\n",
            "Epoch 60/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 3.4530e-04 - val_loss: 6.8436e-04\n",
            "Epoch 61/100\n",
            "2048/2048 [==============================] - 1s 378us/sample - loss: 3.1500e-04 - val_loss: 3.9014e-04\n",
            "Epoch 62/100\n",
            "2048/2048 [==============================] - 1s 391us/sample - loss: 3.5115e-04 - val_loss: 3.6481e-04\n",
            "Epoch 63/100\n",
            "2048/2048 [==============================] - 1s 372us/sample - loss: 2.3598e-04 - val_loss: 3.3564e-04\n",
            "Epoch 64/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 2.3218e-04 - val_loss: 3.5375e-04\n",
            "Epoch 65/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 2.7142e-04 - val_loss: 5.6868e-04\n",
            "Epoch 66/100\n",
            "2048/2048 [==============================] - 1s 374us/sample - loss: 2.4084e-04 - val_loss: 3.2738e-04\n",
            "Epoch 67/100\n",
            "2048/2048 [==============================] - 1s 380us/sample - loss: 2.2024e-04 - val_loss: 3.3599e-04\n",
            "Epoch 68/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 2.3178e-04 - val_loss: 3.5495e-04\n",
            "Epoch 69/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 2.1101e-04 - val_loss: 4.3018e-04\n",
            "Epoch 70/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 2.0371e-04 - val_loss: 3.5472e-04\n",
            "Epoch 71/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 2.0258e-04 - val_loss: 3.3046e-04\n",
            "Epoch 72/100\n",
            "2048/2048 [==============================] - 1s 376us/sample - loss: 1.9843e-04 - val_loss: 4.4951e-04\n",
            "Epoch 73/100\n",
            "2048/2048 [==============================] - 1s 381us/sample - loss: 2.3387e-04 - val_loss: 4.4407e-04\n",
            "Epoch 74/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 3.7605e-04 - val_loss: 6.4153e-04\n",
            "Epoch 75/100\n",
            "2048/2048 [==============================] - 1s 403us/sample - loss: 2.8436e-04 - val_loss: 2.8527e-04\n",
            "Epoch 76/100\n",
            "2048/2048 [==============================] - 1s 380us/sample - loss: 2.4649e-04 - val_loss: 3.3422e-04\n",
            "Epoch 77/100\n",
            "2048/2048 [==============================] - 1s 375us/sample - loss: 1.8600e-04 - val_loss: 2.6893e-04\n",
            "Epoch 78/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 1.7625e-04 - val_loss: 2.4948e-04\n",
            "Epoch 79/100\n",
            "2048/2048 [==============================] - 1s 387us/sample - loss: 1.9322e-04 - val_loss: 2.2513e-04\n",
            "Epoch 80/100\n",
            "2048/2048 [==============================] - 1s 404us/sample - loss: 1.7194e-04 - val_loss: 2.6895e-04\n",
            "Epoch 81/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 1.4620e-04 - val_loss: 2.4970e-04\n",
            "Epoch 82/100\n",
            "2048/2048 [==============================] - 1s 381us/sample - loss: 1.5686e-04 - val_loss: 2.2538e-04\n",
            "Epoch 83/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 1.9133e-04 - val_loss: 2.1716e-04\n",
            "Epoch 84/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 1.7152e-04 - val_loss: 2.9251e-04\n",
            "Epoch 85/100\n",
            "2048/2048 [==============================] - 1s 408us/sample - loss: 2.1699e-04 - val_loss: 3.1411e-04\n",
            "Epoch 86/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 3.4156e-04 - val_loss: 2.6269e-04\n",
            "Epoch 87/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 1.8164e-04 - val_loss: 2.0244e-04\n",
            "Epoch 88/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 1.6200e-04 - val_loss: 2.6285e-04\n",
            "Epoch 89/100\n",
            "2048/2048 [==============================] - 1s 396us/sample - loss: 1.3010e-04 - val_loss: 1.9790e-04\n",
            "Epoch 90/100\n",
            "2048/2048 [==============================] - 1s 379us/sample - loss: 1.7958e-04 - val_loss: 2.3456e-04\n",
            "Epoch 91/100\n",
            "2048/2048 [==============================] - 1s 380us/sample - loss: 1.8492e-04 - val_loss: 1.9823e-04\n",
            "Epoch 92/100\n",
            "2048/2048 [==============================] - 1s 379us/sample - loss: 1.2535e-04 - val_loss: 1.8778e-04\n",
            "Epoch 93/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 1.3634e-04 - val_loss: 2.3232e-04\n",
            "Epoch 94/100\n",
            "2048/2048 [==============================] - 1s 383us/sample - loss: 1.7570e-04 - val_loss: 4.5689e-04\n",
            "Epoch 95/100\n",
            "2048/2048 [==============================] - 1s 382us/sample - loss: 2.4348e-04 - val_loss: 1.6795e-04\n",
            "Epoch 96/100\n",
            "2048/2048 [==============================] - 1s 377us/sample - loss: 1.3555e-04 - val_loss: 3.3545e-04\n",
            "Epoch 97/100\n",
            "2048/2048 [==============================] - 1s 384us/sample - loss: 1.5980e-04 - val_loss: 1.9999e-04\n",
            "Epoch 98/100\n",
            "2048/2048 [==============================] - 1s 380us/sample - loss: 1.2849e-04 - val_loss: 1.8331e-04\n",
            "Epoch 99/100\n",
            "2048/2048 [==============================] - 1s 389us/sample - loss: 1.1463e-04 - val_loss: 1.6896e-04\n",
            "Epoch 100/100\n",
            "2048/2048 [==============================] - 1s 395us/sample - loss: 1.3804e-04 - val_loss: 2.4006e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJU5WZJ_j_61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d7627d4f-0c24-405c-867d-cbe8583b1f11"
      },
      "source": [
        "# 7.17 GRU 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nehGROPf/AWmNzYanE/LdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxtxoNhkbfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1bbd8b8d-c811-4874-de7c-a02d8bcd41bf"
      },
      "source": [
        "# 7.18 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        cnt += 1\n",
        "print('correctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "440/440 [==============================] - 0s 1ms/sample - loss: 2.1837e-04\n",
            "0.3086555988413602 \t 0.30935803 \tdiff: 0.0007024317162722671\n",
            "0.0068629519465001464 \t 0.0055766366 \tdiff: 0.0012863153042825103\n",
            "0.5237953747841952 \t 0.5400483 \tdiff: 0.01625292643574494\n",
            "0.08709619625243772 \t 0.08767998 \tdiff: 0.0005837859329260453\n",
            "0.4376509525255051 \t 0.4409368 \tdiff: 0.003285851292243902\n",
            "correctness: 99.0909090909091 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdCQLRxBkgf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7.19 Naver Sentiment Movie Corpus v1.0 다운로드\n",
        "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0qDwwIIkoGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "efaa1062-3a62-49f2-ab01-53c88a993681"
      },
      "source": [
        "# 7.20 데이터 로드 및 확인\n",
        "# 데이터를 메모리에 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
        "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# 텍스트가 총 몇 자인지 확인합니다.\n",
        "print('Length of text: {} characters'.format(len(train_text)))\n",
        "print('Length of text: {} characters'.format(len(test_text)))\n",
        "print()\n",
        "\n",
        "# 처음 300 자를 확인해봅니다.\n",
        "print(train_text[:300])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 6937271 characters\n",
            "Length of text: 2318260 characters\n",
            "\n",
            "id\tdocument\tlabel\n",
            "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
            "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
            "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
            "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
            "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
            "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
            "7797314\t원작의\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev-_NeFPl1Sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "87b48a60-06ac-449a-888a-d7c51b78afed"
      },
      "source": [
        "# 7.21 학습을 위한 정답 데이터(Y) 만들기\n",
        "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "test_Y = np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "print(train_Y.shape, test_Y.shape)\n",
        "print(train_Y[:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 1) (50000, 1)\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKE4SWe1mHKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "3ff5e303-7087-43de-9e4a-95a08cc4a1c1"
      },
      "source": [
        "# 7.22 train 데이터의 입력(X)에 대한 정제(Cleaning)\n",
        "import re\n",
        "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string.lower()\n",
        "\n",
        "\n",
        "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
        "# 문장을 띄어쓰기 단위로 단어 분리\n",
        "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
        "for i in range(5):\n",
        "    print(sentences[i])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
            "['흠', '포스터보고', '초딩영화줄', '오버연기조차', '가볍지', '않구나']\n",
            "['너무재밓었다그래서보는것을추천한다']\n",
            "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
            "['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCTCkpj5mcgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "785ded1a-4a50-49e6-f67e-74d4f4848fa8"
      },
      "source": [
        "# 7.23 각 문장의 단어 길이 확인\n",
        "import matplotlib.pyplot as plt\n",
        "sentence_len = [len(sentence) for sentence in sentences]\n",
        "sentence_len.sort()\n",
        "plt.plot(sentence_len)\n",
        "plt.show()\n",
        "\n",
        "print(sum([int(l<=25) for l in sentence_len]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngjLAJamgDHBJKqj/Dx/rGwQpAqHJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "142587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5XrH5yrmoab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f076e93e-bd66-4e78-a90e-ea3f777e940d"
      },
      "source": [
        "# 7.24 단어 정제 및 문장 길이 줄임\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "    sentences_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "for i in range(5):\n",
        "    print(sentences[i])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
            "['흠', '포스터보고', '초딩영화줄', '오버연기조', '가볍지', '않구나']\n",
            "['너무재밓었']\n",
            "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
            "['사이몬페그', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨', '늙어보이기', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpmmvE3omxaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "388a250a-e9be-41f5-a356-40d2740f92ad"
      },
      "source": [
        "# 7.25 Tokenizer와 pad_sequences를 사용한 문장 전처리\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "train_X = tokenizer.texts_to_sequences(sentences)\n",
        "train_X = pad_sequences(train_X, padding='post')\n",
        "\n",
        "print(train_X[:5])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   25   884     8  5795  1111     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  588  5796  6697     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   71   346    31    35 10468     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  106  5338     4     2  2169   869   573     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgem43sEm_7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "09cdfb26-c440-4220-a4fa-e2d38c63bdc7"
      },
      "source": [
        "# 7.26 Tokenizer의 동작 확인\n",
        "print(tokenizer.index_word[19999])\n",
        "print(tokenizer.index_word[20000])\n",
        "temp = tokenizer.texts_to_sequences(['#$#$#', '경우는', '잊혀질', '연기가'])\n",
        "print(temp)\n",
        "temp = pad_sequences(temp, padding='post')\n",
        "print(temp)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "경우는\n",
            "잊혀질\n",
            "[[], [19999], [], [106]]\n",
            "[[    0]\n",
            " [19999]\n",
            " [    0]\n",
            " [  106]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N06pR4b-nWfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9960c01d-e4b2-445f-c764-5fabf69f8512"
      },
      "source": [
        "# 7.27 감성 분석을 위한 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
        "    tf.keras.layers.LSTM(units=50),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           6000000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                70200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 6,070,302\n",
            "Trainable params: 6,070,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3lG-88GnZB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "697ddb30-1a66-4857-a3f2-e05f97476707"
      },
      "source": [
        "# 7.28 감성 분석 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 120000 samples, validate on 30000 samples\n",
            "Epoch 1/5\n",
            "120000/120000 [==============================] - 59s 488us/sample - loss: 0.4335 - accuracy: 0.7849 - val_loss: 0.3874 - val_accuracy: 0.8177\n",
            "Epoch 2/5\n",
            "120000/120000 [==============================] - 57s 474us/sample - loss: 0.3249 - accuracy: 0.8480 - val_loss: 0.3916 - val_accuracy: 0.8170\n",
            "Epoch 3/5\n",
            "120000/120000 [==============================] - 57s 476us/sample - loss: 0.2718 - accuracy: 0.8699 - val_loss: 0.4086 - val_accuracy: 0.8162\n",
            "Epoch 4/5\n",
            "120000/120000 [==============================] - 57s 473us/sample - loss: 0.2266 - accuracy: 0.8895 - val_loss: 0.4917 - val_accuracy: 0.8144\n",
            "Epoch 5/5\n",
            "120000/120000 [==============================] - 57s 474us/sample - loss: 0.1919 - accuracy: 0.9050 - val_loss: 0.5661 - val_accuracy: 0.8084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcpWGV8YniJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "30c3ef10-bbbe-4cb2-9ffa-bf09d2f24c3d"
      },
      "source": [
        "# 7.29 감성 분석 모델 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEKCAYAAADgochqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el0oAguNn0_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ad1f72d-4c94-4ba3-bbac-b09768fd316a"
      },
      "source": [
        "# 7.30 테스트 데이터 평가\n",
        "test_text_X = [row.split('\\t')[1] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
        "sentences = [sentence.split(' ') for sentence in test_text_X]\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "    sentences_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(sentences)\n",
        "test_X = pad_sequences(test_X, padding='post')\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.576878777551651, 0.80256]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXgQOsnln7JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "3dadf693-dff7-4c28-8588-66bd9ce25b25"
      },
      "source": [
        "# 7.31 임의의 문장 감성 분석 결과 확인\n",
        "test_sentence = '재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다.'\n",
        "test_sentence = test_sentence.split(' ')\n",
        "test_sentences = []\n",
        "now_sentence = []\n",
        "for word in test_sentence:\n",
        "    now_sentence.append(word)\n",
        "    test_sentences.append(now_sentence[:])\n",
        "    \n",
        "test_X_1 = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_X_1 = pad_sequences(test_X_1, padding='post', maxlen=25)\n",
        "prediction = model.predict(test_X_1)\n",
        "for idx, sentence in enumerate(test_sentences):\n",
        "    print(sentence)\n",
        "    print(prediction[idx])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['재미있을']\n",
            "[0.14346986 0.8565302 ]\n",
            "['재미있을', '줄']\n",
            "[0.19314875 0.8068512 ]\n",
            "['재미있을', '줄', '알았는데']\n",
            "[0.3304111 0.6695889]\n",
            "['재미있을', '줄', '알았는데', '완전']\n",
            "[0.44440296 0.55559707]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.']\n",
            "[0.44440296 0.55559707]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무']\n",
            "[0.74112785 0.25887218]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고']\n",
            "[0.9888554  0.01114458]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이']\n",
            "[0.9984787  0.00152135]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이', '아까웠다.']\n",
            "[0.9984787  0.00152135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crISaDbIqP62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7.32 조선왕조실록 데이터 파일 다운로드\n",
        "path_to_file = tf.keras.utils.get_file('input.txt', 'http://bit.ly/2Mc3SOV')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OKID9PftBZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b6392e16-b564-4c5e-e3ab-f5f1f9f86a3d"
      },
      "source": [
        "# 7.33 데이터 로드 및 확인\n",
        "# 데이터를 메모리에 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# 텍스트가 총 몇 자인지 확인합니다.\n",
        "print('Length of text: {} characters'.format(len(train_text)))\n",
        "print()\n",
        "\n",
        "# 처음 100 자를 확인해봅니다.\n",
        "print(train_text[:100])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 26265493 characters\n",
            "\n",
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX0qDzCQvkJN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "116c8e74-2371-4041-adc0-e8a4915cbe97"
      },
      "source": [
        "# 7.34 훈련 데이터 입력 정제\n",
        "import re\n",
        "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \"\", string)\n",
        "    string = re.sub(r\"\\)\", \"\", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string\n",
        "\n",
        "\n",
        "train_text = train_text.split('\\n')\n",
        "train_text = [clean_str(sentence) for sentence in train_text]\n",
        "train_text_X = []\n",
        "for sentence in train_text:\n",
        "    train_text_X.extend(sentence.split(' '))\n",
        "    train_text_X.append('\\n')\n",
        "    \n",
        "train_text_X = [word for word in train_text_X if word != '']\n",
        "\n",
        "print(train_text_X[:20])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnFaOUjmvy7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "923bd7da-9fad-4430-ae8a-b6a90985f080"
      },
      "source": [
        "# 7.35 단어 토큰화\n",
        "# 단어의 set을 만듭니다.\n",
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append('UNK')\n",
        "print ('{} unique words'.format(len(vocab)))\n",
        "\n",
        "# vocab list를 숫자로 맵핑하고, 반대도 실행합니다.\n",
        "word2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2word = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([word2idx[c] for c in train_text_X])\n",
        "\n",
        "# word2idx 의 일부를 알아보기 쉽게 print 해봅니다.\n",
        "print('{')\n",
        "for word,_ in zip(word2idx, range(10)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(word), word2idx[word]))\n",
        "print('  ...\\n}')\n",
        "\n",
        "print('index of UNK: {}'.format(word2idx['UNK']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "332640 unique words\n",
            "{\n",
            "  '\\n':   0,\n",
            "  '!' :   1,\n",
            "  ',' :   2,\n",
            "  '000명으로':   3,\n",
            "  '001':   4,\n",
            "  '002':   5,\n",
            "  '003':   6,\n",
            "  '004':   7,\n",
            "  '005':   8,\n",
            "  '006':   9,\n",
            "  ...\n",
            "}\n",
            "index of UNK: 332639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gV0OHawv7Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c5a62d9e-963f-443f-e34f-16a871f1d1d7"
      },
      "source": [
        "# 7.36 토큰 데이터 확인\n",
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3MR8XWev-p6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "66e8f46e-e917-4e48-f887-fff1e0c7262f"
      },
      "source": [
        "# 7.37 기본 데이터셋 만들기\n",
        "seq_length = 25\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "sentence_dataset = sentence_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for item in sentence_dataset.take(1):\n",
        "    print(idx2word[item.numpy()])\n",
        "    print(item.numpy())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',' '휘']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2 330313]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmPuxIR5wIgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "02e00ff4-d1ec-4fc7-ad95-d5b599a34cbf"
      },
      "source": [
        "# 7.38 학습 데이터셋 만들기\n",
        "def split_input_target(chunk):\n",
        "    return [chunk[:-1], chunk[-1]]\n",
        "\n",
        "train_dataset = sentence_dataset.map(split_input_target)\n",
        "for x,y in train_dataset.take(1):\n",
        "    print(idx2word[x.numpy()])\n",
        "    print(x.numpy())\n",
        "    print(idx2word[y.numpy()])\n",
        "    print(y.numpy())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2]\n",
            "휘\n",
            "330313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN7tsfoPwS2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7.39 데이터셋 shuffle, batch 설정\n",
        "BATCH_SIZE = 512\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5488EbxwWmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "9f7bbf07-33f9-4d25-a1fe-dfc3eaa93441"
      },
      "source": [
        "# 7.40 단어 단위 생성 모델 정의\n",
        "total_words = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, 100, input_length=seq_length),\n",
        "    tf.keras.layers.LSTM(units=100, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(units=100),\n",
        "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 100)           33264000  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 25, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 332640)            33596640  \n",
            "=================================================================\n",
            "Total params: 67,021,440\n",
            "Trainable params: 67,021,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDNcxmvvwsvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e80c3c5-5564-48aa-c0d6-69fe89c8d4bc"
      },
      "source": [
        "# 7.41 단어 단위 생성 모델 학습\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "    if epoch % 5 != 0 and epoch != 49:\n",
        "        return\n",
        "    test_sentence = train_text[0]\n",
        "\n",
        "    next_words = 100\n",
        "    for _ in range(next_words):\n",
        "        test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "        test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "\n",
        "        output_idx = model.predict_classes(test_text_X)\n",
        "        test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "    \n",
        "    print()\n",
        "    print(test_sentence)\n",
        "    print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=50, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 533 steps\n",
            "Epoch 1/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
            "\n",
            "533/533 - 282s - loss: 9.3726 - accuracy: 0.0721\n",
            "Epoch 2/50\n",
            "533/533 - 275s - loss: 8.3595 - accuracy: 0.0746\n",
            "Epoch 3/50\n",
            "533/533 - 276s - loss: 8.0678 - accuracy: 0.0820\n",
            "Epoch 4/50\n",
            "533/533 - 276s - loss: 7.8077 - accuracy: 0.0907\n",
            "Epoch 5/50\n",
            "533/533 - 280s - loss: 7.5709 - accuracy: 0.1004\n",
            "Epoch 6/50\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  것은 , , 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 말하기를 , \n",
            " 말하기를 , \n",
            " 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 하니 , 임금이\n",
            "\n",
            "533/533 - 282s - loss: 7.3260 - accuracy: 0.1155\n",
            "Epoch 7/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-9bc7b3ede408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtestmodelcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestmodelcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNibjZIEGVKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "6506211a-553d-4000-b45d-fb4f87edef55"
      },
      "source": [
        "# 7.42 임의의 문장을 사용한 생성 결과 확인\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "test_sentence = '동헌에 나가 공무를 본 후 활 십오 순을 쏘았다'\n",
        "\n",
        "next_words = 100\n",
        "for _ in range(next_words):\n",
        "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "    test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "    \n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "\n",
        "print(test_sentence)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동헌에 나가 공무를 본 후 활 십오 순을 쏘았다 아뢰기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 아뢰기를 , \n",
            " 그 아뢰기를 , \n",
            " 그 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 , \n",
            " 아뢰기를 ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzYjDIziHw5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "21f02eab-047e-4be9-cce1-6439ba52be14"
      },
      "source": [
        "# 7.43 jamotools 설치\n",
        "!pip install jamotools"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jamotools\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/d6/ec13c68f7ea6a8085966390d256d183bf8488f8b9770028359acb86df643/jamotools-0.1.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from jamotools) (1.14.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from jamotools) (0.16.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from jamotools) (1.18.1)\n",
            "Installing collected packages: jamotools\n",
            "Successfully installed jamotools-0.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDSdu0f6H059",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e6fcb496-d141-47e4-f9db-1d8017fe6cc4"
      },
      "source": [
        "# 7.44 자모 분리 테스트\n",
        "import jamotools\n",
        "\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "s = train_text[:100]\n",
        "print(s)\n",
        "\n",
        "# 한글 텍스트를 자모 단위로 분리해줍니다. 한자 등에는 영향이 없습니다.\n",
        "s_split = jamotools.split_syllables(s)\n",
        "print(s_split)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n",
            "﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇㅢ ㄱㅏㄱㅖ. ㅁㅗㄱㅈㅗ ㅇㅣㅇㅏㄴㅅㅏㄱㅏ ㅈㅓㄴㅈㅜㅇㅔㅅㅓ ㅅㅏㅁㅊㅓㄱ·ㅇㅢㅈㅜㄹㅡㄹ ㄱㅓㅊㅕ ㅇㅏㄹㄷㅗㅇㅇㅔ ㅈㅓㅇㅊㅏㄱㅎㅏㄷㅏ \n",
            "ㅌㅐㅈㅗ ㄱㅏㅇㅎㅓㄴ ㅈㅣㅇㅣㄴ ㄱㅖㅇㅜㄴ ㅅㅓㅇㅁㅜㄴ ㅅㅣㄴㅁㅜ ㄷㅐㅇㅘㅇ(太祖康獻至仁啓運聖文神武大王)ㅇㅢ ㅅㅓㅇㅇㅡㄴ ㅇㅣㅆㅣ(李氏)ㅇㅛ, ㅎㅟ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRpCuo7oH--t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "deb53437-7a03-43b5-f388-5a273b9021fe"
      },
      "source": [
        "# 7.45 자모 결합 테스트\n",
        "s2 = jamotools.join_jamos(s_split)\n",
        "print(s2)\n",
        "print(s == s2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGe5c5_CIAhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "bd81f72c-1a3d-471b-d32a-2e4ba1991c27"
      },
      "source": [
        "# 7.46 자모 토큰화\n",
        "# 텍스트를 자모 단위로 나눕니다. 데이터가 크기 때문에 약간 시간이 걸립니다.\n",
        "train_text_X = jamotools.split_syllables(train_text)\n",
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append('UNK')\n",
        "print ('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# vocab list를 숫자로 맵핑하고, 반대도 실행합니다.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in train_text_X])\n",
        "\n",
        "# word2idx 의 일부를 알아보기 쉽게 print 해봅니다.\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(10)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')\n",
        "\n",
        "print('index of UNK: {}'.format(char2idx['UNK']))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6198 unique characters\n",
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  \"'\" :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  '+' :   7,\n",
            "  ',' :   8,\n",
            "  '-' :   9,\n",
            "  ...\n",
            "}\n",
            "index of UNK: 6197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYzraOyDIFht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a4f8a560-7bc1-41a2-8e57-4bdf9b5b0242"
      },
      "source": [
        "# 7.47 토큰 데이터 확인\n",
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇ\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-qU5SCnJitt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "b1af0958-c1a3-44e0-e4df-c68dbab5763b"
      },
      "source": [
        "# 7.48 학습 데이터세트 생성\n",
        "seq_length = 80\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "char_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for item in char_dataset.take(1):\n",
        "    print(idx2char[item.numpy()])\n",
        "    print(item.numpy())\n",
        "    \n",
        "def split_input_target(chunk):\n",
        "    return [chunk[:-1], chunk[-1]]\n",
        "\n",
        "train_dataset = char_dataset.map(split_input_target)\n",
        "for x,y in train_dataset.take(1):\n",
        "    print(idx2char[x.numpy()])\n",
        "    print(x.numpy())\n",
        "    print(idx2char[y.numpy()])\n",
        "    print(y.numpy())\n",
        "    \n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff' 'ㅌ' 'ㅐ' 'ㅈ' 'ㅗ' ' ' 'ㅇ' 'ㅣ' 'ㅅ' 'ㅓ' 'ㅇ' 'ㄱ' 'ㅖ' ' ' 'ㅅ' 'ㅓ' 'ㄴ'\n",
            " 'ㄷ' 'ㅐ' 'ㅇ' 'ㅢ' ' ' 'ㄱ' 'ㅏ' 'ㄱ' 'ㅖ' '.' ' ' 'ㅁ' 'ㅗ' 'ㄱ' 'ㅈ' 'ㅗ' ' ' 'ㅇ'\n",
            " 'ㅣ' 'ㅇ' 'ㅏ' 'ㄴ' 'ㅅ' 'ㅏ' 'ㄱ' 'ㅏ' ' ' 'ㅈ' 'ㅓ' 'ㄴ' 'ㅈ' 'ㅜ' 'ㅇ' 'ㅔ' 'ㅅ' 'ㅓ'\n",
            " ' ' 'ㅅ' 'ㅏ' 'ㅁ' 'ㅊ' 'ㅓ' 'ㄱ' '·' 'ㅇ' 'ㅢ' 'ㅈ' 'ㅜ' 'ㄹ' 'ㅡ' 'ㄹ' ' ' 'ㄱ' 'ㅓ'\n",
            " 'ㅊ' 'ㅕ' ' ' 'ㅇ' 'ㅏ' 'ㄹ' 'ㄷ' 'ㅗ' 'ㅇ' 'ㅇ']\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78  105    1   56   86   56   93   10    1\n",
            "   72   94   56   79   94    1   78  106   78   86   59   76   86   56\n",
            "   86    1   79   90   59   79   99   78   91   76   90    1   76   86\n",
            "   72   81   90   56   36   78  105   79   99   64  104   64    1   56\n",
            "   90   81   92    1   78   86   64   62   94   78   78]\n",
            "['\\ufeff' 'ㅌ' 'ㅐ' 'ㅈ' 'ㅗ' ' ' 'ㅇ' 'ㅣ' 'ㅅ' 'ㅓ' 'ㅇ' 'ㄱ' 'ㅖ' ' ' 'ㅅ' 'ㅓ' 'ㄴ'\n",
            " 'ㄷ' 'ㅐ' 'ㅇ' 'ㅢ' ' ' 'ㄱ' 'ㅏ' 'ㄱ' 'ㅖ' '.' ' ' 'ㅁ' 'ㅗ' 'ㄱ' 'ㅈ' 'ㅗ' ' ' 'ㅇ'\n",
            " 'ㅣ' 'ㅇ' 'ㅏ' 'ㄴ' 'ㅅ' 'ㅏ' 'ㄱ' 'ㅏ' ' ' 'ㅈ' 'ㅓ' 'ㄴ' 'ㅈ' 'ㅜ' 'ㅇ' 'ㅔ' 'ㅅ' 'ㅓ'\n",
            " ' ' 'ㅅ' 'ㅏ' 'ㅁ' 'ㅊ' 'ㅓ' 'ㄱ' '·' 'ㅇ' 'ㅢ' 'ㅈ' 'ㅜ' 'ㄹ' 'ㅡ' 'ㄹ' ' ' 'ㄱ' 'ㅓ'\n",
            " 'ㅊ' 'ㅕ' ' ' 'ㅇ' 'ㅏ' 'ㄹ' 'ㄷ' 'ㅗ' 'ㅇ']\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78  105    1   56   86   56   93   10    1\n",
            "   72   94   56   79   94    1   78  106   78   86   59   76   86   56\n",
            "   86    1   79   90   59   79   99   78   91   76   90    1   76   86\n",
            "   72   81   90   56   36   78  105   79   99   64  104   64    1   56\n",
            "   90   81   92    1   78   86   64   62   94   78]\n",
            "ㅇ\n",
            "78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3v3Lr5JpU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "34103df4-4779-4c71-9a04-f0f0b53c0d87"
      },
      "source": [
        "# 7.49 자소 단위 생성 모델 정의\n",
        "total_chars = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_chars, 100, input_length=seq_length),\n",
        "    tf.keras.layers.LSTM(units=400),\n",
        "    tf.keras.layers.Dense(total_chars, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 80, 100)           619800    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 400)               801600    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6198)              2485398   \n",
            "=================================================================\n",
            "Total params: 3,906,798\n",
            "Trainable params: 3,906,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaL21G6JuCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "16500724-6b77-4f5d-e6fe-a2c8271f2380"
      },
      "source": [
        "# 7.50 자소 단위 생성 모델 학습\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "    if epoch % 5 != 0 and epoch != 99:\n",
        "        return\n",
        "    \n",
        "    test_sentence = train_text[:48]\n",
        "    test_sentence = jamotools.split_syllables(test_sentence)\n",
        "\n",
        "    next_chars = 300\n",
        "    for _ in range(next_chars):\n",
        "        test_text_X = test_sentence[-seq_length:]\n",
        "        test_text_X = np.array([char2idx[c] if c in char2idx else char2idx['UNK'] for c in test_text_X])\n",
        "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=char2idx['UNK'])\n",
        "\n",
        "        output_idx = model.predict_classes(test_text_X)\n",
        "        test_sentence += idx2char[output_idx[0]]\n",
        "    \n",
        "    print()\n",
        "    print(jamotools.join_jamos(test_sentence))\n",
        "    print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=100, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 2364 steps\n",
            "Epoch 1/100\n",
            "\n",
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 임을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을 것을\n",
            "\n",
            "2364/2364 - 154s - loss: 2.5918 - accuracy: 0.3060\n",
            "Epoch 2/100\n",
            "2364/2364 - 144s - loss: 1.9842 - accuracy: 0.4279\n",
            "Epoch 3/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-8408df2d616a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtestmodelcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestmodelcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KvIrwg5K8JN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6751f4b8-3b09-4bb8-a4df-c4e3c7dbabb8"
      },
      "source": [
        "# 7.51 임의의 문장을 사용한 생성 결과 확인\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "test_sentence = '동헌에 나가 공무를 본 후 활 십오 순을 쏘았다'\n",
        "test_sentence = jamotools.split_syllables(test_sentence)\n",
        "\n",
        "next_chars = 300\n",
        "for _ in range(next_chars):\n",
        "    test_text_X = test_sentence[-seq_length:]\n",
        "    test_text_X = np.array([char2idx[c] if c in char2idx else char2idx['UNK'] for c in test_text_X])\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=char2idx['UNK'])\n",
        "    \n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += idx2char[output_idx[0]]\n",
        "    \n",
        "\n",
        "print(jamotools.join_jamos(test_sentence))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동헌에 나가 공무를 본 후 활 십오 순을 쏘았다. 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 있으니, 임금이 ㅇ\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}